# ML Pipeline Automation with Databricks

[![Databricks](https://img.shields.io/badge/Databricks-Platform-blue)](https://databricks.com/)
[![PySpark](https://img.shields.io/badge/PySpark-3.5.0-orange)](https://spark.apache.org/)
[![AWS](https://img.shields.io/badge/AWS-S3%2C%20SageMaker-yellow)](https://aws.amazon.com/)

Automated ML pipelines for model training and deployment on Databricks, integrated with AWS S3 and SageMaker.

## Key Features
- **Cluster Optimization**: Reduced training time by 40% via dynamic autoscaling.
- **CI/CD**: Automated model retraining with GitHub Actions.
- **Reproducibility**: Versioned datasets and models using MLflow.

## Usage
1. Clone the repository.
2. Configure AWS credentials in `~/.aws/credentials`.
3. Schedule pipeline via Databricks CLI:
   ```bash
   databricks jobs submit --python-file databricks_pipeline.py
